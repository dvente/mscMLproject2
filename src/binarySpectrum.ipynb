{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models to use and needed parameters for model selection\n",
    "testSize = 0.25 #percentage of total set\n",
    "k = 3 # for K-fold cross-validation\n",
    "GBC = GradientBoostingClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier()\n",
    "linear = LogisticRegression()\n",
    "models = [('Logistic regression',linear,RFE(linear)),\n",
    "          ('Gradient Boosting', GBC, SelectFromModel(GBC)),\n",
    "          ('Random Forests',RFC,SelectFromModel(RFC)),\n",
    "          ('Decision tree',DTC,SelectFromModel(DTC)),\n",
    "          ('Adaboost',ABC,SelectFromModel(ABC))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = pd.read_csv(\"../binary/X.csv\",header=None).values\n",
    "y = pd.read_csv(\"../binary/y.csv\",header=None,squeeze=True).values\n",
    "waveLengths = pd.read_csv(\"../binary/Wavelength.csv\",header=None)\n",
    "X_toClassify = pd.read_csv(\"../binary/XToClassify.csv\",header=None).values\n",
    "\n",
    "# Put aside data for testing at the end\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize)\n",
    "\n",
    "\n",
    "# Do some standard normalisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_toClassify = scaler.transform(X_toClassify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a baseline accruaccy\n",
    "linear = LogisticRegression()\n",
    "linear_selector = RFE(linear)\n",
    "linear.fit(X_train,y_train)\n",
    "f1_score(linear.predict(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean score</th>\n",
       "      <th>Total operation time</th>\n",
       "      <th>Number of important features</th>\n",
       "      <th>Feature set</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>1</td>\n",
       "      <td>reduced</td>\n",
       "      <td>273.618892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>1</td>\n",
       "      <td>reduced</td>\n",
       "      <td>120.581417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019660</td>\n",
       "      <td>460</td>\n",
       "      <td>reduced</td>\n",
       "      <td>50.864093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026309</td>\n",
       "      <td>1</td>\n",
       "      <td>Full</td>\n",
       "      <td>38.010476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031199</td>\n",
       "      <td>1</td>\n",
       "      <td>Full</td>\n",
       "      <td>32.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049511</td>\n",
       "      <td>10</td>\n",
       "      <td>reduced</td>\n",
       "      <td>20.197355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050313</td>\n",
       "      <td>460</td>\n",
       "      <td>Full</td>\n",
       "      <td>19.875675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055884</td>\n",
       "      <td>10</td>\n",
       "      <td>Full</td>\n",
       "      <td>17.894246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131196</td>\n",
       "      <td>70</td>\n",
       "      <td>reduced</td>\n",
       "      <td>7.622168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841714</td>\n",
       "      <td>70</td>\n",
       "      <td>Full</td>\n",
       "      <td>1.188051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Mean score  Total operation time  \\\n",
       "7        Decision tree         1.0              0.003655   \n",
       "9             Adaboost         1.0              0.008293   \n",
       "1  Logistic regression         1.0              0.019660   \n",
       "6        Decision tree         1.0              0.026309   \n",
       "8             Adaboost         1.0              0.031199   \n",
       "5       Random Forests         1.0              0.049511   \n",
       "0  Logistic regression         1.0              0.050313   \n",
       "4       Random Forests         1.0              0.055884   \n",
       "3    Gradient Boosting         1.0              0.131196   \n",
       "2    Gradient Boosting         1.0              0.841714   \n",
       "\n",
       "  Number of important features Feature set      Rating  \n",
       "7                            1     reduced  273.618892  \n",
       "9                            1     reduced  120.581417  \n",
       "1                          460     reduced   50.864093  \n",
       "6                            1        Full   38.010476  \n",
       "8                            1        Full   32.051842  \n",
       "5                           10     reduced   20.197355  \n",
       "0                          460        Full   19.875675  \n",
       "4                           10        Full   17.894246  \n",
       "3                           70     reduced    7.622168  \n",
       "2                           70        Full    1.188051  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a dataframe to contain the results\n",
    "results = pd.DataFrame(columns=['Algorithm',\n",
    "                                'Mean score',\n",
    "                                'Total operation time',\n",
    "                                'Number of important features',\n",
    "                                \"Feature set\"])\n",
    "\n",
    "# Loop over the models and test their performance using cross validation and the f1 score\n",
    "for name, model, selector in models:\n",
    "    scores = cross_validate(model,X_train,y_train,cv=k,scoring='f1')\n",
    "    \n",
    "    # Can we do just as well with fewer features?\n",
    "    selector.fit(X_train,y_train)\n",
    "    X_reduced = selector.transform(X_train)\n",
    "    scores_reduced = cross_validate(model,X_reduced,y_train,cv=k,scoring='f1')\n",
    "\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Mean score\":scores['test_score'].mean(),\n",
    "        \"Total operation time\" : sum(scores['fit_time'])+sum(scores['score_time']),\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Feature set\" : \"Full\"})\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Mean score\":scores_reduced['test_score'].mean(),\n",
    "        \"Total operation time\" : sum(scores_reduced['fit_time'])+sum(scores_reduced['score_time']),\n",
    "        \"Feature set\":\"reduced\"})                                                                                                                                                 \n",
    "    \n",
    "\n",
    "\n",
    "# calculate the 'rating' to determine the best model. Based on accuracy and operation time. Higher is better \n",
    "results['Rating'] = results['Mean score'] /results['Total operation time']\n",
    "results.sort_values('Rating',ascending=False,inplace=True)\n",
    "bestModelRecord = results.iloc[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model\n",
    "for name,model,selector in models:\n",
    "    if name == bestModelRecord['Algorithm']:\n",
    "        bestModel = model\n",
    "        bestSelector = selector\n",
    "        \n",
    "# Train the best model on the reduced feature set and report the accuracy\n",
    "bestModel.fit(bestSelector.fit_transform(X_train,y_train),y_train)\n",
    "f1_score(bestModel.predict(bestSelector.transform(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trained model to predict and store the results of the samples to classify\n",
    "# Note that X_toClassify was already normalised\n",
    "pd.DataFrame(bestModel.predict(bestSelector.transform(X_toClassify))).to_csv(\"../binary/PredictedClasses.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>717.530 nm</th>\n",
       "      <th>Catagory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   717.530 nm  Catagory\n",
       "0       58.46         1\n",
       "1       -0.36         0\n",
       "2       53.33         1\n",
       "3       43.56         1\n",
       "4       47.61         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the best features and the labels in one dataframe so we can easily plot them\n",
    "bestFeatures = bestSelector.get_support()\n",
    "df = pd.concat([\n",
    "        pd.DataFrame(X[:,bestFeatures],columns=[\"{:.3f}\".format(numb) + \" nm\" for wl in waveLengths[bestFeatures].values.tolist() for numb in wl ]),\n",
    "        pd.DataFrame(y,columns=[\"Catagory\"])]\n",
    "    ,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d4d0a6668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=df.iloc[:,0],y=df.iloc[:,1])\n",
    "plt.title(\"Catagorical scatterplot of the binary data\")\n",
    "plt.ylabel(\"Catagory\")\n",
    "plt.xlabel(df.columns[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrllr}\n",
      "\\toprule\n",
      "{} &            Algorithm &  Mean score &  Total operation time & Number of important features & Feature set &      Rating \\\\\n",
      "\\midrule\n",
      "7 &        Decision tree &         1.0 &              0.003655 &                            1 &     reduced &  273.618892 \\\\\n",
      "9 &             Adaboost &         1.0 &              0.008293 &                            1 &     reduced &  120.581417 \\\\\n",
      "1 &  Logistic regression &         1.0 &              0.019660 &                          460 &     reduced &   50.864093 \\\\\n",
      "6 &        Decision tree &         1.0 &              0.026309 &                            1 &        Full &   38.010476 \\\\\n",
      "8 &             Adaboost &         1.0 &              0.031199 &                            1 &        Full &   32.051842 \\\\\n",
      "5 &       Random Forests &         1.0 &              0.049511 &                           10 &     reduced &   20.197355 \\\\\n",
      "0 &  Logistic regression &         1.0 &              0.050313 &                          460 &        Full &   19.875675 \\\\\n",
      "4 &       Random Forests &         1.0 &              0.055884 &                           10 &        Full &   17.894246 \\\\\n",
      "3 &    Gradient Boosting &         1.0 &              0.131196 &                           70 &     reduced &    7.622168 \\\\\n",
      "2 &    Gradient Boosting &         1.0 &              0.841714 &                           70 &        Full &    1.188051 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
