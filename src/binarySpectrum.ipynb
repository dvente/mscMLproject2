{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models to use and needed parameters for model selection\n",
    "testSize = 0.25 #percentage of total set\n",
    "k = 3 # for K-fold cross-validation\n",
    "GBC = GradientBoostingClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier()\n",
    "linear = LogisticRegression()\n",
    "models = [('Logistic regression',linear,RFE(linear)),\n",
    "          ('Gradient Boosting', GBC, SelectFromModel(GBC)),\n",
    "          ('Random Forests',RFC,SelectFromModel(RFC)),\n",
    "          ('Decision tree',DTC,SelectFromModel(DTC)),\n",
    "          ('Adaboost',ABC,SelectFromModel(ABC))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = pd.read_csv(\"../binary/X.csv\",header=None).values\n",
    "y = pd.read_csv(\"../binary/y.csv\",header=None,squeeze=True).values\n",
    "waveLengths = pd.read_csv(\"../binary/Wavelength.csv\",header=None)\n",
    "X_toClassify = pd.read_csv(\"../binary/XToClassify.csv\",header=None).values\n",
    "\n",
    "# Put aside data for testing at the end\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize)\n",
    "\n",
    "\n",
    "# Do some standard normalisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_toClassify = scaler.transform(X_toClassify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a baseline accruaccy\n",
    "linear = LogisticRegression()\n",
    "linear_selector = RFE(linear)\n",
    "linear.fit(X_train,y_train)\n",
    "f1_score(linear.predict(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean score</th>\n",
       "      <th>Total operation time</th>\n",
       "      <th>Number of important features</th>\n",
       "      <th>Feature set</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>1</td>\n",
       "      <td>reduced</td>\n",
       "      <td>166.884335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>1</td>\n",
       "      <td>reduced</td>\n",
       "      <td>99.384025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021063</td>\n",
       "      <td>460</td>\n",
       "      <td>reduced</td>\n",
       "      <td>47.477491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040967</td>\n",
       "      <td>460</td>\n",
       "      <td>Full</td>\n",
       "      <td>24.409898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047222</td>\n",
       "      <td>1</td>\n",
       "      <td>Full</td>\n",
       "      <td>21.176509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>1</td>\n",
       "      <td>Full</td>\n",
       "      <td>18.600100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070952</td>\n",
       "      <td>10</td>\n",
       "      <td>reduced</td>\n",
       "      <td>14.094095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077141</td>\n",
       "      <td>10</td>\n",
       "      <td>Full</td>\n",
       "      <td>12.963347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193892</td>\n",
       "      <td>72</td>\n",
       "      <td>reduced</td>\n",
       "      <td>5.157517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.080912</td>\n",
       "      <td>72</td>\n",
       "      <td>Full</td>\n",
       "      <td>0.925145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Mean score  Total operation time  \\\n",
       "7        Decision tree         1.0              0.005992   \n",
       "9             Adaboost         1.0              0.010062   \n",
       "1  Logistic regression         1.0              0.021063   \n",
       "0  Logistic regression         1.0              0.040967   \n",
       "6        Decision tree         1.0              0.047222   \n",
       "8             Adaboost         1.0              0.053763   \n",
       "5       Random Forests         1.0              0.070952   \n",
       "4       Random Forests         1.0              0.077141   \n",
       "3    Gradient Boosting         1.0              0.193892   \n",
       "2    Gradient Boosting         1.0              1.080912   \n",
       "\n",
       "  Number of important features Feature set      Rating  \n",
       "7                            1     reduced  166.884335  \n",
       "9                            1     reduced   99.384025  \n",
       "1                          460     reduced   47.477491  \n",
       "0                          460        Full   24.409898  \n",
       "6                            1        Full   21.176509  \n",
       "8                            1        Full   18.600100  \n",
       "5                           10     reduced   14.094095  \n",
       "4                           10        Full   12.963347  \n",
       "3                           72     reduced    5.157517  \n",
       "2                           72        Full    0.925145  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a dataframe to contain the results\n",
    "results = pd.DataFrame(columns=['Algorithm',\n",
    "                                'Mean score',\n",
    "                                'Total operation time',\n",
    "                                'Number of important features',\n",
    "                                \"Feature set\"])\n",
    "\n",
    "# Loop over the models and test their performance using cross validation and the f1 score\n",
    "for name, model, selector in models:\n",
    "    scores = cross_validate(model,X_train,y_train,cv=k,scoring='f1')\n",
    "    \n",
    "    # Can we do just as well with fewer features?\n",
    "    selector.fit(X_train,y_train)\n",
    "    X_reduced = selector.transform(X_train)\n",
    "    scores_reduced = cross_validate(model,X_reduced,y_train,cv=k,scoring='f1')\n",
    "\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Mean score\":scores['test_score'].mean(),\n",
    "        \"Total operation time\" : sum(scores['fit_time'])+sum(scores['score_time']),\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Feature set\" : \"Full\"})\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Mean score\":scores_reduced['test_score'].mean(),\n",
    "        \"Total operation time\" : sum(scores_reduced['fit_time'])+sum(scores_reduced['score_time']),\n",
    "        \"Feature set\":\"reduced\"})                                                                                                                                                 \n",
    "    \n",
    "\n",
    "\n",
    "# calculate the 'rating' to determine the best model. Based on accuracy and operation time. Higher is better \n",
    "results['Rating'] = results['Mean score'] /results['Total operation time']\n",
    "results.sort_values('Rating',ascending=False,inplace=True)\n",
    "bestModelRecord = results.iloc[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model\n",
    "for name,model,selector in models:\n",
    "    if name == bestModelRecord['Algorithm']:\n",
    "        bestModel = model\n",
    "        bestSelector = selector\n",
    "        \n",
    "# Train the best model on the reduced feature set and report the accuracy\n",
    "bestModel.fit(bestSelector.fit_transform(X_train,y_train),y_train)\n",
    "f1_score(bestModel.predict(bestSelector.transform(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trained model to predict and store the results of the samples to classify\n",
    "# Note that X_toClassify was already normalised\n",
    "pd.DataFrame(bestModel.predict(bestSelector.transform(X_toClassify))).to_csv(\"../binary/PredictedClasses.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>637.352 nm</th>\n",
       "      <th>Catagory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   637.352 nm  Catagory\n",
       "0       55.16         1\n",
       "1       10.81         0\n",
       "2       50.74         1\n",
       "3       50.99         1\n",
       "4       52.40         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the best features and the labels in one dataframe so we can easily plot them\n",
    "bestFeatures = bestSelector.get_support()\n",
    "df = pd.concat([\n",
    "        pd.DataFrame(X[:,bestFeatures],columns=[\"{:.3f}\".format(numb) + \" nm\" for wl in waveLengths[bestFeatures].values.tolist() for numb in wl ]),\n",
    "        pd.DataFrame(y,columns=[\"Catagory\"])]\n",
    "    ,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHd9JREFUeJzt3XucHFWd9/HPN5OJJNwCZHQlFwIS\nEHC5rPMgCrIguEZXkriCgqJGUVZXRJSNi5cFxPWy5vGCD+y6iCiigogaI8YnugriKigTA2jAaEQw\nIUFGSAIBhCT89o86c1Lp9Ez3JFPTyfT3/XrNa7pOnTr9q+rq+nWfU1WtiMDMzAxgVKsDMDOz7YeT\ngpmZZU4KZmaWOSmYmVnmpGBmZpmTgpmZZU4K1i9JSyQdt41tXCjpy0MU0nZJ0mxJ/zNMz3WgpMWS\nHpF0dpPLhKT9h+C5p6a2Rvcz/32SLt/W56mCpBslvbnVcewInBQqJuk1knokrZO0StL3JB3T5LJD\n8mbeWhFxSETc2Krn3xqS7pF0Yml6wAPZcBuCg9N7gBsjYteI+EwF7W+1iPhIROzwB97afajdOClU\nSNK7gU8DHwGeAUwB/gOY2cq4GtleDqDbg+1wW+wDLGl1EMNpO3wNRraI8F8Ff8DuwDrglAHqHAnc\nDKwBVgGXAGPSvJuAAB5N7bwa2AO4HugFVqfHk0rt7ZuWewT4b+BS4Mul+TMoDihrgBuBg0rz7gH+\nBbgDeAIYncpOTPM7gPcBv0/tLwImp3kXA8uBh1P5C0vtXliOoWb9J6R1WAM8BPwEGJXmTQa+mdb1\nQeCSVP4s4Eep7M/AV4Dxad5VwFPA42mbvQf4Y9qO69Lf81PdNwF3pe24ENinFFcAbwd+B/yhVHY2\ncHd63rmlWGcD/1Na/gXArcDa9P8FqfzDwEbgLymWS/rZLnVfp7Te5eUPqFmubvsp9rem9Vmd9guV\nlut3W9S0PzW1dSawkmKfPbfea12q+4b0GvwZeH8z+3691yDF/ImaeL4DnNNPrC8GfpNeg0uAHwNv\n3pp9KJV/Hbg/tXcTcEirjzGVHbtaHcBI/QOmAxuA0QPUeS5wFMUBeGp6Y55Tmh/A/qXpvYBXAuOA\nXdOOOq80/2bg/wJjgGMoDtJ9b9IDKBLMi4FOigPmMjYloXuA2ygOxmNLZX1JYQ7wK+BAQMBhwF5p\n3ukpttHAuenNs1Oalw8Uddb/o8BnUzydwAtT2x3A7cCngJ2BnYBj0jL7p3V4GtCV3qCfLrWZY07T\nU9N2HF0qm5XW/aAU8weAn9Vs9x8Ae5a2RQA3pLIpwG/ZdJCZTUoKaf5q4HWp7dPSdN+2urFvuX62\nSaPXqdHyW8xPsV8PjE+x9wLTm9kWNe30bcur0+vy16mtvn0kv9alup8Dxqb95Qk2Jbhm9v38GlAk\nkZVsSsQTgMeAZ9SJcwLFvn9y2obvongv9r1eg9qHUtmbKN5zT6P49n9bq48xlR27Wh3ASP0DXgvc\nP8hlzgG+VZreLCnUqX84sDo9npJ2/HGl+V8uvUn/Fbi2NG8UcB9wXJq+B3hTTfv5zQEsBWY2uR6r\ngcPS43ygqFPvIuDbtesIPD8dbPpNqKW6s4DF9WJO030Hp3JS+B5wRs22eIz0CTnVf1HN8wTpQJqm\n/wn4YXo8m01J4XXAL2qWvRmYnR7fyMAH9UavU6Plt5ifYj+mNH0tcF4z26Kmnb5t+exS2ceBz9e+\n1qW65W+yvwBOHcS+X/sa3AW8OD0+C1jQT1uvB24pTQtY0d92a7QP1ak/PsW3ezPvhx3tz2MK1XkQ\nmDBQf6ikAyRdL+l+SQ9TjD1MGKD+OEn/JeneVP8mYLykDmBv4KGIeKy0yPLS472Be/smIuKpNH9i\nP/VrTaboOqoX17mS7pK0VtIaiq6zftejZC7Fp9TvS7pb0nml57o3IjbUea6nS7pG0n1pG3y5yecq\n2we4WNKaFO9DFAeORtuiXHYvxTattdl2LtWdWKduPc28Tlvj/tLjx4Bd0uNmtkWtZrbDgM/b5L5f\n+xpcSfGtlPT/qn6ec+/yslEcyfP0YPchSR2SPibp96n+PWnWYPe7HYKTQnVupujbnTVAnf+k6Pec\nFhG7UfTZa4D651J03zwv1T82lYuiX3ZPSeNK9SeXHq+kOAAUC0hK8+8r1YkBnns5RV/sZiS9kGIs\n4lXAHhExnqLfdaD1KJ4s4pGIODci9gNOAt4t6YT0XFP6SagfTXEemrbB6TXPVbsO9dZpOfCPETG+\n9Dc2In7WYLny9pxCsU1rbbadS3X7tvNA23iL5ft5nQbSqP1azWyLWs1sh0aa2fdr1+XLwExJh1F0\nd83rp+1V5RhL27DPYPeh11CcHHIixQeeqX1N9/P8OzQnhYpExFrgfOBSSbPSp/xOSS+V9PFUbVeK\nvs91kp4NvK2mmT8B+5Wmd6UYAFsjaU/ggtLz3Qv0ABdKGiPp+RQH2j7XAn8v6QRJnRQJ5glgoDd/\n2eXAhyRNU+FQSXulmDaQunsknQ/s1kyDkl4uaf/0pn2YYpB0I0U3wyrgY5J2lrSTpKNL22Bd2gYT\nKcY6ymq3WS/FwGG57LPAeyUdkuLYXdIpTYQ8R9IekiYD7wS+VqfOAuCAdCryaEmvBg6m6NOvF1+t\nbX2dGrVfa2u2xb+m/fkQ4I3U3w6NNNr3txARKygG7q8CvhERj/dT9bvAIZL+IX2wOBv4q5rnHsw+\ntCvFa/AgxXjeRxrFukNrdf/VSP+jGFvooRg8vJ9ih+07G+VYik9L6yjOvLmIzc9ieSvFwXENxSfx\nvSn6jNdRDHT+I6X+copP8j+hODvoh8BlpP7eNP8VwJ0Un+R/TOkMCuoPruUyisHfD1CcCfIIxZtz\nUir/PMUbfBXFwGh5uQvpf0zhXanuoxR9vv9amjeF4pNg3xkin0nlh1Cc4bSOYmD8XGBFabmZFGe7\nrAH+OZVdRJEc1gBHpbLXUQycP0zxafmKUhtbjOWw+dlHDwKfADrSvNk1r9sxKca16X+5P//56bVb\n3bdOdbbLQK/TjQw8prBF+7XrA3wR+LfSdL/boqbtqWx+9tH9pLNzal9r6o/l5NhpvO/XHU+j+FQf\nwPEN3nfT03aod/bRoPYhii6vb1Ps9/dSjFkMON63I/8pbQQbgSR9DfhNRFzQsLINSFJQdHUsa3Us\n7UzSsRTdSFOjGG+xIebuoxFE0v+R9CxJoyRNp/jE01+/q9kOJXWnvRO43AmhOr5ScGT5K4oLvvai\n6I55W0Qsbm1IZttO0kEU3bC3U4xjWEXcfWRmZpm7j8zMLNvhuo8mTJgQU6dObXUYZmY7lEWLFv05\nIroa1dvhksLUqVPp6elpdRhmZjsUSbVX2tfl7iMzM8ucFMzMLHNSMDOzzEnBzMwyJwUzM8ucFMzM\nLHNSMDOzzEnBzMyyyi5ek3QF8HLggYh4Tp35Ai4GXkbxM32zI+KXVcVjZtuveYvv48L5S1jz+HoA\n9hjXyQUnHcKsI+r/Kui8xfcxd+FSVq55nL3Hj+X4Z3dx/e2r8vI7j+mgs2MUax9fz97jxzLnJQcC\nbPYcw0EM/qfwysZ2juKVz53Ed+9YxerHirjHj+3kwhn9b5ttVdkN8dJ9z9cBX+onKbwMeAdFUnge\ncHFEPK9Ru93d3eErms1GjnmL72PO129n/VObH4s6O8Tckw/b4uA3b/F9vPebv+Lx9Rubfo7OUWJj\nBE+NkPt/do4Sc0/ZctsMRNKiiOhuVK+y7qOIuIniR8D7M5MiYURE3ELxA/TPrCoeM9s+zV24dIuE\nALB+YzB34dK69QeTEADWPzVyEgIU61Nv2wyFVo4pTKT46b8+K1LZFiSdKalHUk9vb++wBGdmw2Pl\nmv5+arn+vIHqt5OqtkMrk4LqlNXN5RFxWUR0R0R3V1fDm/yZ2Q5k7/FjBzVvoPrtpKrt0MqksAKY\nXJqeRPFj4GbWRua85EA6R235GbGzQ3mAuLb+2M6OQT1H5yhR5yl2WJ2j6m+bodDKpDAfeL0KRwFr\nI2JVC+MxsxaYdcRE5p5yGOPHduayPcZ11h1k7qv/0X/4ayaOH4uAiePHcvpRUzZbfucxHYwf25nn\nzz3lMD75qsM3qzMctjUPje0cxelHTWGPcZviHj+2c9CDzINR5dlHVwPHAROAPwEXAJ0AEfHZdErq\nJcB0ilNS3xgRDU8r8tlHZmaD1+zZR5VdpxARpzWYH8Dbq3p+MzMbPF/RbGZmmZOCmZllTgpmZpY5\nKZiZWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZll\nTgpmZpY5KZiZWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZm\nmZOCmZllTgpmZpY5KZiZWeakYGZmWaVJQdJ0SUslLZN0Xp35UyTdIGmxpDskvazKeMzMbGCVJQVJ\nHcClwEuBg4HTJB1cU+0DwLURcQRwKvAfVcVjZmaNVflN4UhgWUTcHRFPAtcAM2vqBLBberw7sLLC\neMzMrIEqk8JEYHlpekUqK7sQOF3SCmAB8I56DUk6U1KPpJ7e3t4qYjUzM6pNCqpTFjXTpwFfjIhJ\nwMuAqyRtEVNEXBYR3RHR3dXVVUGoZmYG1SaFFcDk0vQktuweOgO4FiAibgZ2AiZUGJOZmQ2gyqRw\nKzBN0r6SxlAMJM+vqfNH4AQASQdRJAX3D5mZtUhlSSEiNgBnAQuBuyjOMloi6SJJM1K1c4G3SLod\nuBqYHRG1XUxmZjZMRlfZeEQsoBhALpedX3p8J3B0lTGYmVnzfEWzmZllTgpmZpY5KZiZWeakYGZm\nmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZllTgpmZpY5KZiZ\nWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZllTgpmZpY5KZiZWeakYGZmmZOCmZllTgpm\nZpY5KZiZWeakYGZmmZOCmZllTgpmZpZVmhQkTZe0VNIySef1U+dVku6UtETSV6uMx8zMBja6qoYl\ndQCXAi8GVgC3SpofEXeW6kwD3gscHRGrJT29qnjMzKyxpr4ppAP8YB0JLIuIuyPiSeAaYGZNnbcA\nl0bEaoCIeGArnsfMzIZIs91HyyTNlXTwINqeCCwvTa9IZWUHAAdI+qmkWyRNr9eQpDMl9Ujq6e3t\nHUQIZmY2GM0mhUOB3wKXp4P3mZJ2a7CM6pRFzfRoYBpwHHBaan/8FgtFXBYR3RHR3dXV1WTIZmY2\nWE0lhYh4JCI+FxEvAN4DXACsknSlpP37WWwFMLk0PQlYWafOtyNifUT8AVhKkSTMzKwFmh5TkDRD\n0reAi4FPAPsB3wEW9LPYrcA0SftKGgOcCsyvqTMPOD49xwSK7qS7B70WZmY2JJo9++h3wA3A3Ij4\nWan8OknH1lsgIjZIOgtYCHQAV0TEEkkXAT0RMT/N+ztJdwIbgTkR8eDWroyZmW0bRdR289dUKM48\nen9EXDQ8IQ2su7s7enp6Wh2GmdkORdKiiOhuVK9h91FEbCR18ZiZ2cjWbPfRzyRdAnwNeLSvMCJ+\nWUlUZmbWEs0mhRek/+UupABeNLThmJlZKzWVFCLC3UdmZm2g2VNSd5f0yb6riiV9QtLuVQdnZmbD\nq9krmq8AHgFelf4eBr5QVVBmZtYazY4pPCsiXlma/qCk26oIyMzMWqfZbwqPSzqmb0LS0cDj1YRk\nZmat0uw3hbcBV6ZxBAEPAbOrCsrMzFqj2bOPbgMO67szakQ8XGlUZmbWEk0lBUnvrpkGWAssSgnD\nzMxGgGbHFLqBt1L8SM5E4EyK30D4nKT3VBOamZkNt2bHFPYC/iYi1gFIugC4DjgWWAR8vJrwzMxs\nODX7TWEK8GRpej2wT0Q8Djwx5FGZmVlLNPtN4avALZK+naZPAq6WtDNwZyWRmZnZsGv27KMPSfoe\ncDTFKalvjYi+HzV4bVXBmZnZ8Gr2mwIR0SPpj8BOAJKmRMQfK4vMzMyGXbM3xJsh6XfAH4Afp//f\nqzIwMzMbfs0ONH8IOAr4bUTsC5wI/LSyqMzMrCWaTQrrI+JBYJSkURFxA3B4hXGZmVkLNDumsEbS\nLsBNwFckPQBsqC4sMzNrhWa/KcwEHgPeBfx/4PfAy6sKyszMWqPZpHB+RDwVERsi4sqI+AzwL1UG\nZmZmw6/ZpPDiOmUvHcpAzMys9QYcU5D0NuCfgP0k3VGatSs++8jMbMRpNND8VYrrET4KnFcqfyQi\nHqosKjMza4kBk0JErKX43YTTACQ9neKK5l0k7eIrms3MRpZmr2g+qeaK5nvwFc1mZiNOswPN/8bm\nVzSfgMcUzMxGnEqvaJY0XdJSScsknTdAvZMlhaTuJuMxM7MKVHZFs6QO4FKK01lXALdKmh8Rd9bU\n2xU4G/j5YIM3M7OhNeA3BUn7SzqaLa9ofhB4R4O2jwSWRcTdEfEkcE1qp9aHKH7O8y+DjN3MzIZY\no+6jT1Ocfvpo+YpmYAFwYYNlJwLLS9MrUlkm6QhgckRcP1BDks6U1COpp7e3t8HTmpnZ1mqUFKZG\nxB21helX16Y2WFZ1yiLPlEYBnwLObdAOEXFZRHRHRHdXV1ej6mZmtpUaJYWdBpg3tsGyK4DJpelJ\nwMrS9K7Ac4AbJd1DcXbTfA82m5m1TqOkcKukt9QWSjoDWNRoWWCapH0ljQFOBeb3zYyItRExISKm\nRsRU4BZgRum3n83MbJg1OvvoHOBbkl7LpiTQDYwBXjHQghGxQdJZwEKgA7giIpZIugjoiYj5Ay1v\nZmbDTxHRuJJ0PEVXD8CSiPhRpVENoLu7O3p6/GXCzGwwJC2KiIbd801dp5AuVrthm6MyM7PtWrNX\nNJuZWRtwUjAzs8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczM\nMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCxzUjAz\ns8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCyrNClImi5pqaRlks6rM//dku6U\ndIekH0rap8p4zMxsYJUlBUkdwKXAS4GDgdMkHVxTbTHQHRGHAtcBH68qHjMza6zKbwpHAssi4u6I\neBK4BphZrhARN0TEY2nyFmBShfGYmVkDVSaFicDy0vSKVNafM4Dv1Zsh6UxJPZJ6ent7hzBEMzMr\nqzIpqE5Z1K0onQ50A3PrzY+IyyKiOyK6u7q6hjBEMzMrG11h2yuAyaXpScDK2kqSTgTeD/xtRDxR\nYTxmZtZAld8UbgWmSdpX0hjgVGB+uYKkI4D/AmZExAMVxmJmZk2oLClExAbgLGAhcBdwbUQskXSR\npBmp2lxgF+Drkm6TNL+f5szMbBhU2X1ERCwAFtSUnV96fGKVz29mZoPjK5rNzCxzUjAzs8xJwczM\nMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCxzUjAz\ns8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTMzCxzUjAzs8xJwczMMicFMzPLnBTM\nzCxzUjAzs8xJwczMMicFMzPLnBTMzCwbXWXjkqYDFwMdwOUR8bGa+U8DvgQ8F3gQeHVE3DPUccxb\nfB8f/M4SVj+2fpva6RBsjOLxHuM6ueCkQ5h1xMQhiNDMbPtQ2TcFSR3ApcBLgYOB0yQdXFPtDGB1\nROwPfAr496GOY97i+5hz3e3bnBBgU0IAWP3YeuZcdzvzFt+3ze2amW0vquw+OhJYFhF3R8STwDXA\nzJo6M4Er0+PrgBMkaSiDmLtwKevLR/MhtH5jMHfh0kraNjNrhSqTwkRgeWl6RSqrWyciNgBrgb1q\nG5J0pqQeST29vb2DCmLlmscHVX+wqm7fzGw4VZkU6n3ir/3I3kwdIuKyiOiOiO6urq5BBbH3+LGD\nqj9YVbdvZjacqkwKK4DJpelJwMr+6kgaDewOPDSUQcx5yYF0dgxpj1TW2SHmvOTASto2M2uFKpPC\nrcA0SftKGgOcCsyvqTMfeEN6fDLwo4gY0gGAWUdMZO7Jh7HHuM5tbqucW/YY18nckw/z2UdmNqJU\ndkpqRGyQdBawkOKU1CsiYomki4CeiJgPfB64StIyim8Ip1YRy6wjJvrgbWbWhEqvU4iIBcCCmrLz\nS4//ApxSZQxmZtY8X9FsZmaZk4KZmWVOCmZmljkpmJlZ5qRgZmaZk4KZmWVOCmZmlmmILyCunKRe\n4N4Kmp4A/LmCdncE7bzu4PVv5/Vvp3XfJyIa3jxuh0sKVZHUExHdrY6jFdp53cHr387r387r3h93\nH5mZWeakYGZmmZPCJpe1OoAWaud1B69/O69/O697XR5TMDOzzN8UzMwsc1IwM7OsLZOCpCskPSDp\n16WyPSX9QNLv0v89WhljVSRNlnSDpLskLZH0zlTeLuu/k6RfSLo9rf8HU/m+kn6e1v9r6dcCRyRJ\nHZIWS7o+TbfTut8j6VeSbpPUk8raYt9vVlsmBeCLwPSasvOAH0bENOCHaXok2gCcGxEHAUcBb5d0\nMO2z/k8AL4qIw4DDgemSjgL+HfhUWv/VwBktjLFq7wTuKk2307oDHB8Rh5euT2iXfb8pbZkUIuIm\nip//LJsJXJkeXwnMGtaghklErIqIX6bHj1AcHCbSPusfEbEuTXamvwBeBFyXykfs+kuaBPw9cHma\nFm2y7gNoi32/WW2ZFPrxjIhYBcWBE3h6i+OpnKSpwBHAz2mj9U/dJ7cBDwA/AH4PrImIDanKCopE\nORJ9GngP8FSa3ov2WXcoPgB8X9IiSWemsrbZ95tR6W802/ZL0i7AN4BzIuLh4gNje4iIjcDhksYD\n3wIOqldteKOqnqSXAw9ExCJJx/UV16k64ta95OiIWCnp6cAPJP2m1QFtb/xNYZM/SXomQPr/QIvj\nqYykToqE8JWI+GYqbpv17xMRa4AbKcZWxkvq+5A0CVjZqrgqdDQwQ9I9wDUU3Uafpj3WHYCIWJn+\nP0DxgeBI2nDfH4iTwibzgTekx28Avt3CWCqT+pA/D9wVEZ8szWqX9e9K3xCQNBY4kWJc5Qbg5FRt\nRK5/RLw3IiZFxFTgVOBHEfFa2mDdASTtLGnXvsfA3wG/pk32/Wa15RXNkq4GjqO4be6fgAuAecC1\nwBTgj8ApEVE7GL3Dk3QM8BPgV2zqV34fxbhCO6z/oRSDiR0UH4qujYiLJO1H8el5T2AxcHpEPNG6\nSKuVuo/+OSJe3i7rntbzW2lyNPDViPiwpL1og32/WW2ZFMzMrD53H5mZWeakYGZmmZOCmZllTgpm\nZpY5KZiZWeakYCOSpPGSrpP0m3RH2Oen8g9JuiPdJfP7kvZO5XNS2W2Sfi1po6Q967T7+XSH1TtS\n+7uk8tmSekttvDmVHy7p5nRH1jskvXo4t4PZYPmUVBuRJF0J/CQiLk+3gh4XEWsk7RYRD6c6ZwMH\nR8Rba5Y9CXhXRLyoTrvl5T9JcduIj0maDXRHxFk19Q+guA/f71ICWgQclK6mNtvu+N5HNuJI2g04\nFpgNEBFPAk+mxw+Xqu5M/fv8nAZcXa/tUkIQMLaf5cv1f1t6vFLSA0AXsFlSkHQjxQWExwPjgTMi\n4icp2cyiuNjuOcAngDHA6yhuA/6ydr7Qyoaeu49sJNoP6AW+kH5M5vJ0WwMAJH1Y0nLgtcD55QUl\njaP4rY1v9Ne4pC8A9wPPBv5fadYrS91Kk+ssdyTFAf33/TQ9OiKOBM6huMq+z3OA11Dcp+fDwGMR\ncQRwM/D6/uI02xpOCjYSjQb+BvjPdPB8lNIPp0TE+yNiMvAV4KyaZU8CfjrQp++IeCOwN8U9k/rG\nCL4DTI2IQ4H/ZtP9+YF8o7WrgDdGxFPU13dzwkXA1FL5DRHxSET0AmvTc0Fxq5JyPbNt5qRgI9EK\nYEVE/DxNX0eRJGp9FXhlTdmp9NN1VJZuv/21vuUj4sHS/YI+Bzy3r27qzvou8IGIuGWAZvuW38jm\nXbvl+xA9VZp+CncB2xBzUrARJyLuB5ZLOjAVnQDcCSBpWqnqDCDfT1/S7sDf0s9dMlXYv+8xxbeK\n36TpZ9a0e1cqH0NxE7YvRcTXt3nlzCrmTxk2Ur0D+Eo6KN8NvDGVfywli6eAe4HymUevAL4fEY+W\nG5K0AHgzxTjClemTv4DbgbelamdLmkHxG9gPkQa5gVdRDHrvlQaNAWZHxG1DtJ5mQ8qnpJqZWebu\nIzMzy5wUzMwsc1IwM7PMScHMzDInBTMzy5wUzMwsc1IwM7PsfwHjCbbwidRxVwAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f492867cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=df.iloc[:,0],y=df.iloc[:,1])\n",
    "plt.title(\"Catagorical scatterplot of the binary data\")\n",
    "plt.ylabel(\"Catagory\")\n",
    "plt.xlabel(df.columns[0])\n",
    "plt.savefig('../tex/binaryScatterplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrllr}\n",
      "\\toprule\n",
      "{} &            Algorithm &  Mean score &  Total operation time & Number of important features & Feature set &      Rating \\\\\n",
      "\\midrule\n",
      "7 &        Decision tree &         1.0 &              0.003655 &                            1 &     reduced &  273.618892 \\\\\n",
      "9 &             Adaboost &         1.0 &              0.008293 &                            1 &     reduced &  120.581417 \\\\\n",
      "1 &  Logistic regression &         1.0 &              0.019660 &                          460 &     reduced &   50.864093 \\\\\n",
      "6 &        Decision tree &         1.0 &              0.026309 &                            1 &        Full &   38.010476 \\\\\n",
      "8 &             Adaboost &         1.0 &              0.031199 &                            1 &        Full &   32.051842 \\\\\n",
      "5 &       Random Forests &         1.0 &              0.049511 &                           10 &     reduced &   20.197355 \\\\\n",
      "0 &  Logistic regression &         1.0 &              0.050313 &                          460 &        Full &   19.875675 \\\\\n",
      "4 &       Random Forests &         1.0 &              0.055884 &                           10 &        Full &   17.894246 \\\\\n",
      "3 &    Gradient Boosting &         1.0 &              0.131196 &                           70 &     reduced &    7.622168 \\\\\n",
      "2 &    Gradient Boosting &         1.0 &              0.841714 &                           70 &        Full &    1.188051 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
