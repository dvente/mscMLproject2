{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models to use and needed parameters for model selection\n",
    "testSize = 0.25 #percentage of total set\n",
    "k = 3 # for K-fold cross-validation\n",
    "GBC = GradientBoostingClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier()\n",
    "models = [('Logistic regression',linear,RFE(linear)),\n",
    "          ('Gradient Boosting', GBC, SelectFromModel(GBC)),\n",
    "          ('Random Forests',RFC,SelectFromModel(RFC)),\n",
    "          ('Decision tree',DTC,SelectFromModel(DTC)),\n",
    "          ('Adaboost',ABC,SelectFromModel(ABC))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = pd.read_csv(\"../binary/X.csv\",header=None).values\n",
    "y = pd.read_csv(\"../binary/y.csv\",header=None,squeeze=True).values\n",
    "waveLengths = pd.read_csv(\"../binary/Wavelength.csv\",header=None)\n",
    "X_toClassify = pd.read_csv(\"../binary/XToClassify.csv\",header=None).values\n",
    "\n",
    "# Put aside data for testing at the end\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize)\n",
    "\n",
    "\n",
    "# Do some standard normalisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_toClassify = scaler.transform(X_toClassify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a baseline accruaccy\n",
    "linear = LogisticRegression()\n",
    "linear_selector = RFE(linear)\n",
    "linear.fit(X_train,y_train)\n",
    "f1_score(linear.predict(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean score</th>\n",
       "      <th>Total operation time on full feature set</th>\n",
       "      <th>Number of important features</th>\n",
       "      <th>Mean score on reduced feature set</th>\n",
       "      <th>Total operation time on reduced feature set</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022912</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>351.222911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>151.358811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>95.169359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050409</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>22.215358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513859</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111914</td>\n",
       "      <td>8.935401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Mean score  Total operation time on full feature set  \\\n",
       "3        Decision tree         1.0                                  0.022912   \n",
       "4             Adaboost         1.0                                  0.027664   \n",
       "0  Logistic regression         1.0                                  0.020285   \n",
       "2       Random Forests         1.0                                  0.050409   \n",
       "1    Gradient Boosting         1.0                                  0.513859   \n",
       "\n",
       "  Number of important features  Mean score on reduced feature set  \\\n",
       "3                            1                                1.0   \n",
       "4                            1                                1.0   \n",
       "0                          460                                1.0   \n",
       "2                           10                                1.0   \n",
       "1                           72                                1.0   \n",
       "\n",
       "   Total operation time on reduced feature set      Rating  \n",
       "3                                     0.002847  351.222911  \n",
       "4                                     0.006607  151.358811  \n",
       "0                                     0.010508   95.169359  \n",
       "2                                     0.045014   22.215358  \n",
       "1                                     0.111914    8.935401  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a dataframe to contain the results\n",
    "results = pd.DataFrame(columns=['Algorithm',\n",
    "                                'Mean score',\n",
    "                                'Total operation time on full feature set',\n",
    "                                'Number of important features',\n",
    "                                \"Mean score on reduced feature set\",\n",
    "                                \"Total operation time on reduced feature set\"])\n",
    "\n",
    "# Loop over the models and test their performance using cross validation and the f1 score\n",
    "for name, model, selector in models:\n",
    "    scores = cross_validate(model,X_train,y_train,cv=k,scoring='f1')\n",
    "    \n",
    "    # Can we do just as well with fewer features?\n",
    "    selector.fit(X_train,y_train)\n",
    "    X_reduced = selector.transform(X_train)\n",
    "    scores_reduced = cross_validate(model,X_reduced,y_train,cv=k,scoring='f1')\n",
    "\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Mean score\":scores['test_score'].mean(),\n",
    "        \"Total operation time on full feature set\" : sum(scores['fit_time'])+sum(scores['score_time']),\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Mean score on reduced feature set\":scores_reduced['test_score'].mean(),\n",
    "        \"Total operation time on reduced feature set\" : sum(scores_reduced['fit_time'])+sum(scores_reduced['score_time'])                                                                                                                                                    \n",
    "    })\n",
    "\n",
    "\n",
    "# calculate the 'rating' to determine the best model. Based on accuracy and operation time. Higher is better \n",
    "results['Rating'] = results['Mean score on reduced feature set'] * 1/results['Total operation time on reduced feature set']\n",
    "results.sort_values('Rating',ascending=False,inplace=True)\n",
    "bestModelRecord = results.iloc[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model\n",
    "for name,model,selector in models:\n",
    "    if name == bestModelRecord['Algorithm']:\n",
    "        bestModel = model\n",
    "        bestSelector = selector\n",
    "        \n",
    "# Train the best model on the reduced feature set and report the accuracy\n",
    "bestModel.fit(bestSelector.fit_transform(X_train,y_train),y_train)\n",
    "f1_score(bestModel.predict(bestSelector.transform(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trained model to predict and store the results of the samples to classify\n",
    "# Note that X_toClassify was already normalised\n",
    "pd.DataFrame(bestModel.predict(bestSelector.transform(X_toClassify))).to_csv(\"../binary/PredictedClasses.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
