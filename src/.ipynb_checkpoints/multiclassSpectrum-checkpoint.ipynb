{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup models to use and needed parameters for model selection\n",
    "testSize = 0.25 #percentage of total set\n",
    "k = 5 # for K-fold cross-validation\n",
    "GBC = GradientBoostingClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier()\n",
    "linear = LogisticRegression()\n",
    "models = [('Linear',linear,RFE(linear)),\n",
    "          ('Gradient Boosting', GBC, SelectFromModel(GBC)),\n",
    "          ('Random Forests',RFC,SelectFromModel(RFC)),\n",
    "          ('Decision tree',DTC,SelectFromModel(DTC)),\n",
    "          ('Adaboost',ABC,SelectFromModel(ABC))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = pd.read_csv(\"../multiclass/X.csv\",header=None).values\n",
    "y = pd.read_csv(\"../multiclass/y.csv\",header=None,squeeze=True).values\n",
    "waveLengths = pd.read_csv(\"../multiclass/Wavelength.csv\",header=None)\n",
    "X_toClassify = pd.read_csv(\"../multiclass/XtoClassify.csv\",header=None).values\n",
    "# Put aside data for testing at the end\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize)\n",
    "\n",
    "\n",
    "# Do some standard normalisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_toClassify = scaler.transform(X_toClassify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a baseline accruaccy\n",
    "linear = LogisticRegression()\n",
    "linear_selector = RFE(linear)\n",
    "linear.fit(X_train,y_train)\n",
    "f1_score(linear.predict(X_train),y_train,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean score</th>\n",
       "      <th>Total operation time</th>\n",
       "      <th>Number of important features</th>\n",
       "      <th>Feature set</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>5</td>\n",
       "      <td>reduced</td>\n",
       "      <td>142.069840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089206</td>\n",
       "      <td>41</td>\n",
       "      <td>reduced</td>\n",
       "      <td>11.210011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180485</td>\n",
       "      <td>41</td>\n",
       "      <td>Full</td>\n",
       "      <td>5.540641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.967424</td>\n",
       "      <td>0.430177</td>\n",
       "      <td>5</td>\n",
       "      <td>Full</td>\n",
       "      <td>2.248894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607615</td>\n",
       "      <td>460</td>\n",
       "      <td>reduced</td>\n",
       "      <td>1.645778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.810108</td>\n",
       "      <td>0.697904</td>\n",
       "      <td>37</td>\n",
       "      <td>reduced</td>\n",
       "      <td>1.160773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.227268</td>\n",
       "      <td>460</td>\n",
       "      <td>Full</td>\n",
       "      <td>0.814818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.988101</td>\n",
       "      <td>3.010011</td>\n",
       "      <td>94</td>\n",
       "      <td>reduced</td>\n",
       "      <td>0.328272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.795177</td>\n",
       "      <td>8.315187</td>\n",
       "      <td>37</td>\n",
       "      <td>Full</td>\n",
       "      <td>0.095630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.985071</td>\n",
       "      <td>16.606219</td>\n",
       "      <td>94</td>\n",
       "      <td>Full</td>\n",
       "      <td>0.059319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Algorithm  Mean score  Total operation time  \\\n",
       "7      Decision tree    0.997059              0.007018   \n",
       "5     Random Forests    1.000000              0.089206   \n",
       "4     Random Forests    1.000000              0.180485   \n",
       "6      Decision tree    0.967424              0.430177   \n",
       "1             Linear    1.000000              0.607615   \n",
       "9           Adaboost    0.810108              0.697904   \n",
       "0             Linear    1.000000              1.227268   \n",
       "3  Gradient Boosting    0.988101              3.010011   \n",
       "8           Adaboost    0.795177              8.315187   \n",
       "2  Gradient Boosting    0.985071             16.606219   \n",
       "\n",
       "  Number of important features Feature set      Rating  \n",
       "7                            5     reduced  142.069840  \n",
       "5                           41     reduced   11.210011  \n",
       "4                           41        Full    5.540641  \n",
       "6                            5        Full    2.248894  \n",
       "1                          460     reduced    1.645778  \n",
       "9                           37     reduced    1.160773  \n",
       "0                          460        Full    0.814818  \n",
       "3                           94     reduced    0.328272  \n",
       "8                           37        Full    0.095630  \n",
       "2                           94        Full    0.059319  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a dataframe to contain the results\n",
    "results = pd.DataFrame(columns=['Algorithm',\n",
    "                                'Mean score',\n",
    "                                'Total operation time',\n",
    "                                'Number of important features',\n",
    "                                \"Feature set\"])\n",
    "\n",
    "# Loop over the models and test their performance using cross validation and the f1 score\n",
    "for name, model, selector in models:\n",
    "    scores = cross_validate(model,X_train,y_train,cv=k,scoring='f1_micro')\n",
    "    \n",
    "    # Can we do just as well with fewer features?\n",
    "    selector.fit(X_train,y_train)\n",
    "    X_reduced = selector.transform(X_train)\n",
    "    scores_reduced = cross_validate(model,X_reduced,y_train,cv=k,scoring='f1_micro')\n",
    "\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Mean score\":scores['test_score'].mean(),\n",
    "        \"Total operation time\" : sum(scores['fit_time'])+sum(scores['score_time']),\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Feature set\" : \"Full\"})\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Mean score\":scores_reduced['test_score'].mean(),\n",
    "        \"Total operation time\" : sum(scores_reduced['fit_time'])+sum(scores_reduced['score_time']),\n",
    "        \"Feature set\":\"reduced\"})                                                                                                                                                 \n",
    "    \n",
    "\n",
    "\n",
    "# calculate the 'rating' to determine the best model. Based on accuracy and operation time. Higher is better \n",
    "results['Rating'] = results['Mean score'] /results['Total operation time']\n",
    "results.sort_values('Rating',ascending=False,inplace=True)\n",
    "bestModelRecord = results.iloc[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97345132743362828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model\n",
    "for name,model,selector in models:\n",
    "    if name == bestModelRecord['Algorithm']:\n",
    "        bestModel = model\n",
    "        bestSelector = selector\n",
    "        \n",
    "# Train the best model on the reduced feature set and report the accuracy\n",
    "bestModel.fit(bestSelector.fit_transform(X_train,y_train),y_train)\n",
    "f1_score(bestModel.predict(bestSelector.transform(X_test)),y_test,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trained model to predict and store the results of the samples to classify\n",
    "# Note that X_toClassify was already normalised\n",
    "pd.DataFrame(bestModel.predict(bestSelector.transform(X_toClassify))).to_csv(\"../multiclass/PredictedClasses.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>497.713 nm</th>\n",
       "      <th>582.368 nm</th>\n",
       "      <th>632.396 nm</th>\n",
       "      <th>642.301 nm</th>\n",
       "      <th>672.507 nm</th>\n",
       "      <th>Catagory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.09</td>\n",
       "      <td>17.20</td>\n",
       "      <td>10.12</td>\n",
       "      <td>10.12</td>\n",
       "      <td>9.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.71</td>\n",
       "      <td>11.57</td>\n",
       "      <td>46.27</td>\n",
       "      <td>52.46</td>\n",
       "      <td>64.27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.56</td>\n",
       "      <td>60.41</td>\n",
       "      <td>61.59</td>\n",
       "      <td>63.21</td>\n",
       "      <td>58.64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.74</td>\n",
       "      <td>7.92</td>\n",
       "      <td>48.62</td>\n",
       "      <td>53.61</td>\n",
       "      <td>55.23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.59</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   497.713 nm  582.368 nm  632.396 nm  642.301 nm  672.507 nm  Catagory\n",
       "0       15.09       17.20       10.12       10.12        9.17         1\n",
       "1       10.71       11.57       46.27       52.46       64.27         2\n",
       "2       10.56       60.41       61.59       63.21       58.64         4\n",
       "3       -0.74        7.92       48.62       53.61       55.23         3\n",
       "4        7.59        1.93        1.93        0.79        1.28         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the best features and the labels in one dataframe so we can easily plot them\n",
    "bestFeatures = bestSelector.get_support()\n",
    "df = pd.concat([\n",
    "        pd.DataFrame(X[:,bestFeatures],columns=[\"{:.3f}\".format(numb) + \" nm\" for wl in waveLengths[bestFeatures].values.tolist() for numb in wl ]),\n",
    "        pd.DataFrame(y,columns=[\"Catagory\"])]\n",
    "    ,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.savefig('../tex/binaryScatterplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrllr}\n",
      "\\toprule\n",
      "{} &          Algorithm &  Mean score &  Total operation time & Number of important features & Feature set &      Rating \\\\\n",
      "\\midrule\n",
      "7 &      Decision tree &    0.997059 &              0.007018 &                            5 &     reduced &  142.069840 \\\\\n",
      "5 &     Random Forests &    1.000000 &              0.089206 &                           41 &     reduced &   11.210011 \\\\\n",
      "4 &     Random Forests &    1.000000 &              0.180485 &                           41 &        Full &    5.540641 \\\\\n",
      "6 &      Decision tree &    0.967424 &              0.430177 &                            5 &        Full &    2.248894 \\\\\n",
      "1 &             Linear &    1.000000 &              0.607615 &                          460 &     reduced &    1.645778 \\\\\n",
      "9 &           Adaboost &    0.810108 &              0.697904 &                           37 &     reduced &    1.160773 \\\\\n",
      "0 &             Linear &    1.000000 &              1.227268 &                          460 &        Full &    0.814818 \\\\\n",
      "3 &  Gradient Boosting &    0.988101 &              3.010011 &                           94 &     reduced &    0.328272 \\\\\n",
      "8 &           Adaboost &    0.795177 &              8.315187 &                           37 &        Full &    0.095630 \\\\\n",
      "2 &  Gradient Boosting &    0.985071 &             16.606219 &                           94 &        Full &    0.059319 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
