{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models to use and needed parameters for model selection\n",
    "testSize = 0.25 #percentage of total set\n",
    "k = 3 # for K-fold cross-validation\n",
    "linear = LogisticRegression()\n",
    "GBC = GradientBoostingClassifier()\n",
    "RFC = RandomForestClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier()\n",
    "models = [('Logistic regression',linear,RFE(linear)),\n",
    "          ('Gradient Boosting', GBC, SelectFromModel(GBC)),\n",
    "          ('Random Forests',RFC,SelectFromModel(RFC)),\n",
    "          ('Decision tree',DTC,SelectFromModel(DTC)),\n",
    "          ('Adaboost',ABC,SelectFromModel(ABC))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = pd.read_csv(\"../binary/X.csv\",header=None).values\n",
    "y = pd.read_csv(\"../binary/y.csv\",header=None,squeeze=True).values\n",
    "waveLengths = pd.read_csv(\"../binary/Wavelength.csv\",header=None)\n",
    "X_toClassify = pd.read_csv(\"../binary/XToClassify.csv\",header=None).values\n",
    "\n",
    "# Put aside data for testing at the end\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize)\n",
    "\n",
    "\n",
    "# Do some standard normalisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_toClassify = scaler.transform(X_toClassify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = LogisticRegression()\n",
    "linear_selector = RFE(linear)\n",
    "linear.fit(X_train,y_train)\n",
    "f1_score(linear.predict(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean score</th>\n",
       "      <th>Total operation time on full feature set</th>\n",
       "      <th>Number of important features</th>\n",
       "      <th>Mean score on reduced feature set</th>\n",
       "      <th>Total operation time on reduced feature set</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060660</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>165.266717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>86.473363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063668</td>\n",
       "      <td>460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>37.633952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.091240</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076235</td>\n",
       "      <td>13.117325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.370301</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210093</td>\n",
       "      <td>4.759796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Mean score  Total operation time on full feature set  \\\n",
       "3        Decision tree         1.0                                  0.060660   \n",
       "4             Adaboost         1.0                                  0.065143   \n",
       "0  Logistic regression         1.0                                  0.063668   \n",
       "2       Random Forests         1.0                                  0.091240   \n",
       "1    Gradient Boosting         1.0                                  1.370301   \n",
       "\n",
       "  Number of important features  Mean score on reduced feature set  \\\n",
       "3                            1                                1.0   \n",
       "4                            1                                1.0   \n",
       "0                          460                                1.0   \n",
       "2                           10                                1.0   \n",
       "1                           69                                1.0   \n",
       "\n",
       "   Total operation time on reduced feature set      Rating  \n",
       "3                                     0.006051  165.266717  \n",
       "4                                     0.011564   86.473363  \n",
       "0                                     0.026572   37.633952  \n",
       "2                                     0.076235   13.117325  \n",
       "1                                     0.210093    4.759796  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a dataframe to contain the results\n",
    "results = pd.DataFrame(columns=['Algorithm',\n",
    "                                'Mean score',\n",
    "                                'Total operation time on full feature set',\n",
    "                                'Number of important features',\n",
    "                                \"Mean score on reduced feature set\",\n",
    "                                \"Total operation time on reduced feature set\"])\n",
    "\n",
    "# Loop over the models and test their performance using cross validation and the f1 score\n",
    "for name, model, selector in models:\n",
    "    scores = cross_validate(model,X_train,y_train,cv=k,scoring='f1')\n",
    "    \n",
    "    # Can we do just as well with fewer features?\n",
    "    selector.fit(X_train,y_train)\n",
    "    X_reduced = selector.transform(X_train)\n",
    "    scores_reduced = cross_validate(model,X_reduced,y_train,cv=k,scoring='f1')\n",
    "\n",
    "    results.loc[len(results)] = pd.Series({\n",
    "        'Algorithm' : name,\n",
    "        \"Mean score\":scores['test_score'].mean(),\n",
    "        \"Total operation time on full feature set\" : sum(scores['fit_time'])+sum(scores['score_time']),\n",
    "        \"Number of important features\":sum(selector.get_support()),\n",
    "        \"Mean score on reduced feature set\":scores_reduced['test_score'].mean(),\n",
    "        \"Total operation time on reduced feature set\" : sum(scores_reduced['fit_time'])+sum(scores_reduced['score_time'])                                                                                                                                                    \n",
    "    })\n",
    "\n",
    "\n",
    "# calculate the 'rating' to determine the best model. Based on accuracy and operation time. Higher is better \n",
    "results['Rating'] = results['Mean score on reduced feature set'] * 1/results['Total operation time on reduced feature set']\n",
    "results.sort_values('Rating',ascending=False,inplace=True)\n",
    "bestModelRecord = results.iloc[0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model\n",
    "for name,model,selector in models:\n",
    "    if name == bestModelRecord['Algorithm']:\n",
    "        bestModel = model\n",
    "        bestSelector = selector\n",
    "        \n",
    "# Train the best model on the reduced feature set and report the accuracy\n",
    "bestModel.fit(bestSelector.fit_transform(X_train,y_train),y_train)\n",
    "f1_score(bestModel.predict(bestSelector.transform(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trained model to predict and store the results of the samples to classify\n",
    "pd.DataFrame(bestModel.predict(bestSelector.transform(X_toClassify))).to_csv(\"../binary/PredictedClasses.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
